{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "filtering_student.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EC5Ye9zKhZ9"
      },
      "source": [
        "# Part 1 : Sampling and filtering\n",
        "\n",
        "In this part of the lab work, we are going to look at the frequency content of images, and certain filtering operations which which we can carry out.\n",
        "\n",
        "__Note__ : When viewing the result of filtered images, we will avoid using ```plt.imshow()```. Indeed, if you use imshow to display an image, it will change the resolution of this image. Since we are going to be looking at aliasing effects (which is induced precisely by changing resolution), it is better to write the output to an image file and view it in a separate program.\n",
        "\n",
        "However, you can (and will) use ```plt.imshow()``` for displaying the image's spectra and for displaying filters.\n",
        "\n",
        "First, let us load the necessary packages\n",
        "\n",
        "### Your task\n",
        "\n",
        "In the lab work, you must fill in the code in the places marked FILL IN CODE, or answer the written questions directly on the notebook.\n",
        "\n",
        "First, let us load the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJOz8ejPKhZ_"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np \n",
        "import imageio\n",
        "from skimage import color\n",
        "\n",
        "\n",
        "is_colab = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irg13YZPKhaA"
      },
      "source": [
        "The last package will help us to carry out the convolution operation. Let's define two functions to read and write and image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxY10vvWKhaA"
      },
      "source": [
        "def read_image(file_name):\n",
        "    img_color = imageio.imread(file_name)\n",
        "    img_gray = color.rgb2gray(img_color)\n",
        "    return img_gray,img_color\n",
        "    \n",
        "def write_image(img_in,file_name_out):\n",
        "    imageio.imwrite(file_name_out, np.uint8(255.0*img_in))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQL1xGmrKhaA"
      },
      "source": [
        "file_dir = 'images/'\n",
        "file_name = 'boston'\n",
        "file_ext = '.png'\n",
        "\n",
        "if (is_colab == True):\n",
        "  !wget \"https://perso.telecom-paristech.fr/anewson/doc/images/boston.png\"\n",
        "  img_gray,_ = read_image(file_name+file_ext)\n",
        "else:\n",
        "  img_gray,_ = read_image(file_dir+file_name+file_ext)\n",
        "img_gray.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b--dtDqZKhaA"
      },
      "source": [
        "## Frequency content\n",
        "\n",
        "Firstly, we are going to inspect the frequency content of the image. Write a function to display the magnitude of the spectrum of the image. For this, you can use the following functions\n",
        "\n",
        "- ``np.fft.fft2``\n",
        "- ``np.fft.fftshift``\n",
        "\n",
        "The first calculates the 2D Fast Fourier Transform of the image. The second centres the spectrum, such that the 0 frequency is centred in the image. Otherwise the 0 point is set at the top left, which is not very conveniant for visualisation.\n",
        "\n",
        "A final note. It is often the case that the 0 frequency is of much larger amplitude than the other frequencies. Therefore, we often visualise log(1+spectrum_magnitude) rather than spectrum_magnitude itself.\n",
        "\n",
        "Write this function ``display_spectrum`` now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9JtYbCrKhaB"
      },
      "source": [
        "def display_spectrum(img): \n",
        "    # FILL IN CODE\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7N1MgHgKhaB"
      },
      "source": [
        "display_spectrum(img_gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mwqNVc3KhaB"
      },
      "source": [
        "__Question__ : What do you observe in the frequency domain ? What is your interpretation of this image ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBM6yqHUKhaC"
      },
      "source": [
        "__Answer__ :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YY_7Zx_kKhaC"
      },
      "source": [
        "## Subsampling and aliasing\n",
        "\n",
        "We are now going to carry out a ''direct'' subsampling (also known as a ''nearest neighbours'' subsampling) of a factor $\\delta$, that is to say we simply take one out of every $\\delta$ pixels. Fill in the following function to do this :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pi6IsYCNKhaC"
      },
      "source": [
        "def nn_subsampling(img_in,delta):\n",
        "    # FILL IN CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qf9_NftRKhaC"
      },
      "source": [
        "We write the subsampled image, with subsampling step $\\delta = 2$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sbJpZkQFKhaD"
      },
      "source": [
        "delta = 2\n",
        "image_small = nn_subsampling(img_gray,delta)\n",
        "write_image(image_small, file_name+'_subsampled.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_ZOtxvkKhaD"
      },
      "source": [
        "__Question__ What do you notice about the image ? Where is the aliasing taking place ? Why is it taking place in these specific regions ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnyCbHqYKhaD"
      },
      "source": [
        "__Answer__ : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhaAtfAKKhaD"
      },
      "source": [
        "We have seen two different methods of filtering an image before subsampling to remove high frequencies :\n",
        "\n",
        "- Ideal low-pass filter\n",
        "- Gaussian filter\n",
        "\n",
        "We recall that the convolution operation, which defines a filter, can be carried out either in the spatial (image) domain or the frequency domain.\n",
        "\n",
        "First, write a function which filters an input image via the frequency domain, with the input filter ``f_hat`` defined in the frequency domain. The output ``img_out`` should be in the spatial domain. You can use the ``np.fft.ifft2`` function to carry out the inverse Fourier transform. Make sure to take the __real__ part of the output image (``np.real``)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XHrYrHcKhaD"
      },
      "source": [
        "def filter_image(img,f_hat):\n",
        "    \n",
        "    # FILL IN CODE\n",
        "    \n",
        "    return(img_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY3eT6ZbKhaE"
      },
      "source": [
        "### Ideal low-pass filter\n",
        "\n",
        "Now, we are going to create a function ``ideal_low_pass_filter`` which returns an ideal low-pass filter $\\hat{h}$ in the frequency domain. We recall that in 2D this is a disk centred on the 0-frequency (with the radius $\\nu_0$ which is the cut-off freqeuncy).\n",
        "\n",
        "### Creating the disk (low-pass filter) in the frequency domain \n",
        "\n",
        "By definition the 0 frequency is at the top left point of the image. Therefore, you have two options to create the filter :\n",
        "\n",
        "- you can create the low-pass filter in the 'normal' frequency-domain representation, with the 0 frequency at the (0,0) position of the frequency image)\n",
        "- you can create the low-pass filter in the 'centred' position and then ifftshift the frequency image. In the centred representation of the frequency, for an image of even size $n=2a$, the 0 frequency position is located at position $a$ (where 0 is the first position - the '0 indexing' of python).\n",
        "\n",
        "To go between the two representations, you have the following functions :\n",
        "\n",
        "- np.fft.fftshift : top-left centre -> middle centre\n",
        "- np.fft.ifftshift : middle centre -> top-left centre\n",
        "\n",
        "To create the disk centred at the position $a$, you have several options :\n",
        "\n",
        "- use a loop (simplest, but potentially slow)\n",
        "- use the np.meshgrid function, (https://docs.scipy.org/doc/numpy/reference/generated/numpy.meshgrid.html) which creates a grid of positions (in 1D, 2D, etc - here we are interested in 2D)\n",
        "- use the 'distance transform' ``scipy.ndimage.morphology.distance_transform_edt``. This function calculates the distance to the nearest pixel which has a value of 0 in a binary image (this is a mathematical morphology function)\n",
        "- or anything else that you can think of :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c3vu-iRKhaE"
      },
      "source": [
        "from scipy.ndimage.morphology import distance_transform_edt\n",
        "\n",
        "def ideal_low_pass_filter(img_shape,nu_0):\n",
        "    \n",
        "    # FILL IN CODE\n",
        "    \n",
        "    return(f_hat)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGvT_DPDKhaE"
      },
      "source": [
        "__Question__ Given that in an image with sampling rate 1 (the pixel size) the frequencies in the original image of size $n \\times n$ go from $-\\frac{1}{2}$ to $\\frac{1}{2}$.  For a subsampling of $\\delta=2$, where should the cutoff frequency $\\nu_0$ be set for correct subsampling ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsLZ9v8vKhaF"
      },
      "source": [
        "__Answer__ : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gmg379JQKhaF"
      },
      "source": [
        "Create f_hat, the ideal low-pass filter in the frequency domain, and display it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOCYpsu4KhaF"
      },
      "source": [
        "img_shape = img_gray.shape\n",
        "print(img_shape)\n",
        "nu_0 = #FILL IN THIS VALUE\n",
        "f_hat = ideal_low_pass_filter(img_shape,nu_0)\n",
        "plt.imshow(f_hat,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqjVf5rXKhaF"
      },
      "source": [
        "Carry out the filtering, and subsample the image again, and imwrite the result.\n",
        "\n",
        "You should observe that the range of the image is not respected. Make sure to rescale the output image to the range $0, \\dots, 1$ before writing it.\n",
        "\n",
        "__Bonus question__ Why do you think this happens ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrjDJC2VKhaG"
      },
      "source": [
        "__Answer__ :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbjlW29PKhaG"
      },
      "source": [
        "img_filtered = filter_image(img_gray,f_hat)\n",
        "\n",
        "img_filtered = # FILL IN NORMALISATION TO RANGE 0, ..., 1\n",
        "\n",
        "img_filtered = nn_subsampling(img_filtered,delta)\n",
        "\n",
        "write_image(img_filtered,file_name+'_filtered_ideal_low_pass.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKHm4eV9KhaG"
      },
      "source": [
        "__Question__ Is the aliasing reduced ? What effect do you notice in the output ? What is this called ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNPXX95JKhaG"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtGAnx9_KhaG"
      },
      "source": [
        "### Gaussian filter\n",
        "\n",
        "Now, we are going to carry out the filtering with a Gaussian filter. Create a function ``gaussian_filter`` which returns a 2D Gaussian filter, defined as :\n",
        "\n",
        "$g_\\sigma(x,y) = \\frac{1}{2 \\pi \\sigma^2} \\exp{ \\left( - \\frac{x^2+y^x}{2\\sigma^2} \\right)}$\n",
        "\n",
        "To create a grid of pixel positions, you can use the ``np.meshgrid`` function.\n",
        "\n",
        "You must again make sure to carry out an ``ifftshift`` to make sure the filter is in the correct format. Be careful to put the middle of the Gaussian at the centre position ($a$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipegagn5KhaG"
      },
      "source": [
        "def gaussian_filter(img_shape,sigma):\n",
        "    # FILL IN, CREATE g\n",
        "    return g"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF3pPU4UKhaH"
      },
      "source": [
        "Now, create a Gaussian filter in the frequency domain to attenuate the frequencies higher than the previous cutoff frequency you used above, $\\nu_0$. To do this, we recall that 95.45 percent of the energy of a Gaussian function is contained within $\\pm 2\\sigma$. Fix $\\sigma$ accordingly. Display the filter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J082EunjKhaH"
      },
      "source": [
        "sigma = # FILL IN CODE\n",
        "g_hat = gaussian_filter(img_gray.shape,sigma)\n",
        "plt.imshow(g_hat,cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NPZi91yKhaH"
      },
      "source": [
        "Now, carry out the filtering with the Gaussian filter in the frequency domain. Remember to renormalise the output image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NimPHyNsKhaH"
      },
      "source": [
        "img_filtered = filter_image(img_gray,g_hat)\n",
        "# FILL IN NORMALISATION TO 0 ... 1\n",
        "img_filtered = nn_subsampling(img_filtered,delta)\n",
        "\n",
        "write_image(img_filtered,file_name+'_filtered_gaussian.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51gyHbshKhaH"
      },
      "source": [
        "__Question__ Do you still observe the problem observed in the case of the ideal low-pass filter ? Why ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHOnwXetKhaH"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm40csVhKhaI"
      },
      "source": [
        "__Bonus Question__ We have had to rescale the output image again. This time, why was this the case ? Hint : think about a Gaussian filter in the spatial domain with a very large $\\sigma$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcdjzuApKhaI"
      },
      "source": [
        "__Answer__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHmD8lBMKhaI"
      },
      "source": [
        "## Standard filters\n",
        "\n",
        "In this section, we are going to look at some common filters, and see their effects on images. From this point on in the TP, we are going to be working in the spatial domain, and are no longer concentrated on aliasing. Therefore, we can use the plt.imshow function (you may notice some aliasing, but we ignore it here). We define a display function now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN95K2mlKhaI"
      },
      "source": [
        "def display_image(img_in):\n",
        "    # FILL IN CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6Yg6Jh7KhaI"
      },
      "source": [
        "file_dir = 'images/'\n",
        "file_name = 'palma'\n",
        "file_ext = '.png'\n",
        "\n",
        "if (is_colab == True):\n",
        "  !wget \"https://perso.telecom-paristech.fr/anewson/doc/images/palma.png\"\n",
        "  img_gray,_ = read_image(file_name+file_ext)\n",
        "else:\n",
        "  img_gray,_ = read_image(file_dir+file_name+file_ext)\n",
        "img_gray.shape\n",
        "\n",
        "display_image(img_gray)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ny97bMdQKhaI"
      },
      "source": [
        "Now, write a function ``filter_image_spatial`` which carries out the 2D convolution between two images in the spatial domain. For this, you can use the ``convolve2d`` from the scipy.signal package. In this convolution, you should use the following parameters :\n",
        "\n",
        "- mode='same'. This means that the output size of the image will be the same as the input\n",
        "- boundary='symm'. For values outside the image domain, we take the symmetrical values of the image\n",
        "\n",
        "Strictly speaking, if we take the Fourier transform of an image, we are using periodic boudary conditions. However, at this point we no longer need the frequency representation of the image, so we can define the conditions as we wish."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sKHh2mEKhaI"
      },
      "source": [
        "from scipy import signal\n",
        "\n",
        "def filter_image_spatial(img,f):\n",
        "    img_out = # FILL IN CODE\n",
        "    return(img_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tujv84sfKhaJ"
      },
      "source": [
        "Now, define the filters grad_y and grad_x which give the derivatives of the image in the $y$ and $x$ directions, respectively (see lesson slides). Note : you must define these filters in the spatial domain, and make sure that they are matrices (otherwise the dimensions will not match with those of the image);"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UnQ8tgGKhaJ"
      },
      "source": [
        "grad_x = # FILL IN CODE\n",
        "grad_y = # FILL IN CODE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkKZpj5FKhaJ"
      },
      "source": [
        "grad_x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ27Hqi0KhaJ"
      },
      "source": [
        "grad_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSk8ETwNKhaJ"
      },
      "source": [
        "Filter the input image and display the results of these two filterings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "SnMDWyFxKhaJ"
      },
      "source": [
        "img_grad_x = filter_image_spatial(img_gray,grad_x)\n",
        "img_grad_y = filter_image_spatial(img_gray,grad_y)\n",
        "\n",
        "display_image(img_grad_x)\n",
        "plt.figure()\n",
        "display_image(img_grad_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWtlV9OYKhaJ"
      },
      "source": [
        "### Image sketch (edge detection)\n",
        "\n",
        "Suppose we wish to create a sketch of our image, with just the outlines of object. Propose a (simple) method to create a binary image where the edges are detected (using the previous filters and a threshold parameter $\\tau$). Implement this in a function called ``sketch_image``, and apply it to the input image. Display it (you can write it as well to view it better)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "68VHrcCyKhaK"
      },
      "source": [
        "\n",
        "def sketch_image(img_in,tau):\n",
        "    # FILL IN CODE\n",
        "    return img_out\n",
        "\n",
        "tau = # FILL IN CODE\n",
        "img_sketch = sketch_image(img_gray,tau)\n",
        "display_image(img_sketch)\n",
        "write_image(img_sketch, file_name+'_sketch.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxG3x5jCKhaK"
      },
      "source": [
        "## Further refinement (no code to fill in or questions here)\n",
        "\n",
        "Depending on the threshold parameter used in your algorithm, the sketch may have a certain thickness. Ideally, we would like to have a sketch of one-pixel thickness. This is something we would like to avoid in the sketch. In the lesson we saw a morphological operator, the \"skeletonisation\" operator, which you can find the necessary function in the following package :\n",
        "\n",
        "- skimage.morphology\n",
        "\n",
        "Below, we show what this does to the sketch image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSdXU3cuKhaK"
      },
      "source": [
        "\n",
        "from skimage.morphology import skeletonize\n",
        "\n",
        "img_sketch_skeleton = skeletonize(img_sketch)\n",
        "display_image(img_sketch_skeleton)\n",
        "write_image(img_sketch_skeleton, file_name+'_sketch_skeleteon.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}